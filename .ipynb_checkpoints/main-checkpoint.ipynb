{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bb19723",
   "metadata": {},
   "source": [
    "# Learning proteins pockets shape\n",
    "\n",
    "Under development. \n",
    "\n",
    "To allow the notebook to read the cavities data, project's file structure needs to look as the following:\n",
    "\n",
    "```\n",
    "Project\n",
    "├───scPDB\n",
    "│   ├───1a2b_1\n",
    "│   │    └─ cavity6.mol2\n",
    "│   │    │  ...   \n",
    "│   └───1a2f_1\n",
    "│   │   ...\n",
    "└───ThisNotebook.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ca68dd4-2b2d-4d64-9f80-0afe4c6bf484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#torch_geometric \n",
    "from torch_cluster import radius_graph\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_scatter import scatter\n",
    "\n",
    "#e3nn\n",
    "import e3nn\n",
    "from e3nn import o3\n",
    "from e3nn.nn import FullyConnectedNet, Gate\n",
    "from e3nn.o3 import FullyConnectedTensorProduct\n",
    "from e3nn.math import soft_one_hot_linspace\n",
    "from e3nn.nn.models.v2103.gate_points_networks import SimpleNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ce98f82-8c43-4d7f-bcd0-eff2f4e28f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17595it [00:13, 1321.62it/s]\n"
     ]
    }
   ],
   "source": [
    "# First position contains the scPDB directory name\n",
    "paths = [x[0] for x in tqdm(os.walk(os.getcwd()+'/scPDB'))][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8b85fc1-03fc-41ff-ba41-bad472d07951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access every cavity6.mol2 file contained in each folder. Folder == Unique Protein-Cavity\n",
    "\n",
    "# Function retrieves all the data inside cavity6.mol2 file and returns it as a list. \n",
    "def getCavity(path):\n",
    "    prot_path = path.split('/')\n",
    "    file = open(prot_path[-2] + '/' + prot_path[-1] + \"/cavity6.mol2\", \"r\")\n",
    "    data = [line for line in file]\n",
    "#     Get PDB-ID. \n",
    "    pdb_id = prot_path[-1].split('_')[0]\n",
    "    print('Protein:', pdb_id)\n",
    "    return data\n",
    "\n",
    "\n",
    "# Get coordinates of each point of the cavity\n",
    "def getCoordinates(line):\n",
    "    x = float(line.split()[2])\n",
    "    y = float(line.split()[3])\n",
    "    z = float(line.split()[4])\n",
    "\n",
    "    return (x, y, z)\n",
    "\n",
    "# Retrieve pharmacophoric features from the binding site \n",
    "def getFeatures(line):\n",
    "    atom_type = line.split()[1]\n",
    "    \n",
    "    return atom_type\n",
    "    \n",
    "# Extract cavity geometrical data from file\n",
    "def getCavityInfo(data):\n",
    "    # Files follow the same format, starting from 'ATOM' and finishing at 'BOND'\n",
    "    coords = [getCoordinates(atom) for atom in data[data.index('@<TRIPOS>ATOM\\n')+1\n",
    "                                                     :data.index('@<TRIPOS>BOND\\n')]]\n",
    "    \n",
    "    features = [getFeatures(atom) for atom in data[data.index('@<TRIPOS>ATOM\\n')+1\n",
    "                                                     :data.index('@<TRIPOS>BOND\\n')]]\n",
    "    \n",
    "    return torch.tensor(coords, dtype = torch.get_default_dtype()), features\n",
    "\n",
    "\n",
    "# Create labels for each of the cavities. (ONLY DRUGGABLE ATM)\n",
    "def getLabels(cavities) -> torch.Tensor:\n",
    "    return torch.ones(len(cavities), 1)\n",
    "#     return torch.zeros((len(cavities), len(cavities))).fill_diagonal_(1)\n",
    "    \n",
    "\n",
    "# Returns centroid from a given point cloud. Unsqueeze (increase dimensionality) required to compute distance later. \n",
    "def getCentroid(point_cloud) -> torch.Tensor:\n",
    "    return torch.mean(point_cloud, dim = 0).unsqueeze(0)\n",
    "\n",
    "\n",
    "#Compute euclidean distance between two tensors centroids\n",
    "def calculateDistance(t1, t2):\n",
    "    return torch.cdist(getCentroid(t1), getCentroid(t2), p=2).item()\n",
    "\n",
    "\n",
    "# Receives a list of lists. Returns a dict where each key corresponds to an atom type and value is a unique integer.\n",
    "def featuresToDict(feat_list):\n",
    "    # Flat the list of lists \n",
    "    flat_features = [features for sublist in feat_list for features in sublist]\n",
    "\n",
    "    # Reduce to unique features. \n",
    "    unique_features = set(flat_features)\n",
    "\n",
    "    # Generate dictionary for posterior mapping/encoding of features\n",
    "    dict_features = {element:idx for idx, element in enumerate(unique_features)}\n",
    "    \n",
    "    return dict_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b81e7f7a-0abf-4782-b639-9453c384fb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protein: 4j22\n"
     ]
    }
   ],
   "source": [
    "# Number of cavities to be extracted can be set (for now). \n",
    "NUM_PROTEINS = 1\n",
    "\n",
    "cavities, cavities_features = [], []\n",
    "for protein in paths[:NUM_PROTEINS]:\n",
    "    coords, feats = getCavityInfo(getCavity(protein))\n",
    "    cavities.append(coords)\n",
    "    cavities_features.append(feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77839297-7f90-42c1-9ed9-969f33faf090",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Fpocket toy example: 4j22\n",
    "\n",
    "We will conduct a toy example with the first protein obtained from scPDB, 4j22. The goal is to demonstrate that our neural network is able to distinguish between druggable and non-druggable cavities in the protein. Since scPDB provides a single cavity, we will search for more through **fpocket**. All files returned by the algorithm are inside the 'pockets' folder, sorted by their druggability score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aa6701b4-5bfb-40f5-b62e-48a152d69e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "pockets_data = [pocket for pocket in [i[2] for i in os.walk(os.getcwd()+'/pockets')][0] if '.pdb' in pocket]\n",
    "\n",
    "# Reads 'pockets' folder and returns a list of coordinates and atom types for each cavity.\n",
    "def getFpocketCoords(pocket_id):   \n",
    "    coords, features = [], []\n",
    "    # Focus on the lines that contain the coordinates \n",
    "    data = [line for line in open(os.getcwd()+'/pockets/'+pocket_id)][20:-2]\n",
    "    # For each of the lines, extract the coordinates and atom type. \n",
    "    for atom in data:\n",
    "        atom_line_split = atom.split()\n",
    "        # Some files are B''9XX instead of B1XX (hence an additional split between the number and character)\n",
    "        if atom_line_split[5].isdigit() == True:\n",
    "            coords.append(atom_line_split[6:9])\n",
    "        else:\n",
    "            coords.append(atom_line_split[5:8])\n",
    "        features.append(atom_line_split[2])\n",
    "    \n",
    "    return (torch.Tensor(np.array(coords, dtype='float32')), features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "62374ed3-018c-49ba-a8cd-695d677fb8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.776483535766602, 27.861412048339844, 32.577369689941406, 33.63336944580078, 33.588951110839844, 50.967750549316406, 49.08852767944336, 22.45990753173828, 43.91595458984375, 18.20598793029785, 28.26254653930664, 13.513494491577148, 37.019020080566406, 21.109922409057617, 18.126548767089844, 39.27044677734375, 20.355783462524414, 25.32646942138672, 16.542572021484375, 36.99082946777344, 28.47964096069336, 18.026079177856445, 29.520065307617188, 7.529668807983398, 2.0994231700897217, 13.186159133911133]\n"
     ]
    }
   ],
   "source": [
    "pockets, feats = [], []\n",
    "for pid in pockets_data:\n",
    "    p, f = getFpocketCoords(pid)\n",
    "    # There might be (not sure) some errors with the file format. \n",
    "    # Some atom types seem to be mixed with the aminoacid, e.g., CAACYS (CA CYS). Hardcoded solution. Just to make the example work.  \n",
    "    for idx, atom_type in enumerate(f):\n",
    "        if len(atom_type) > 5:\n",
    "            f[idx] = atom_type[:2]\n",
    "    pockets.append(p)\n",
    "    feats.append(f)\n",
    "\n",
    "# Compute euclidean distance between each identified pocket and the one given by scPDB\n",
    "p_distances = [calculateDistance(cavities[0], p) for p in pockets]\n",
    "\n",
    "# All labels are set to 0 except for the one that has the closest distance to the one obtained from scPDB.\n",
    "p_labels = torch.zeros(len(pockets), 1)\n",
    "p_labels[p_distances.index(min(p_distances))] = 1\n",
    "\n",
    "# Generate dictionary where each key is a different atom type and value is a unique integer. \n",
    "dict_features = featuresToDict(feats)\n",
    "\n",
    "print(p_distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a159ac-5cbc-42ae-bcd3-ec86da1498de",
   "metadata": {},
   "source": [
    "As it can be seen, the smallest distance is 2, which compared to the others is quite good. However, fpocket's drug score for that specific cavity ---which should be druggable due to probably corresponding to the one given by scPDB--- is almost 0, hence not considering a potential druggable pocket (doubt). Nevertheless, in order to complete the example, we will consider that cavity as druggable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bd56a6af-b625-4578-b1b6-234a7b0828ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "print(p_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c33e82c-57f9-4f60-830a-84adf20d615e",
   "metadata": {},
   "source": [
    "All labels are 0 (undruggable) except for the one that matches scPDB cavity (druggable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac277895",
   "metadata": {},
   "source": [
    "### Dataset and batch generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e95d1249-97fa-4eb1-92e8-0e58acb4389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to rotate we create a 3x3 rotation matrix and perform a matrix multiplication on the tensor \n",
    "def applyRotation(cavities) -> list:\n",
    "    # Obtain a random 3x3 matrix\n",
    "    rand_matrix = o3.rand_matrix(1)\n",
    "    print('Random matrix:', rand_matrix)\n",
    "    # Multiply cavity coordinates by the random matrix\n",
    "    rotated_set = [torch.matmul(cav, rand_matrix).squeeze(0) for cav in cavities]\n",
    "    \n",
    "    return rotated_set\n",
    "\n",
    "\n",
    "# x: Node feature matrix. [Num_node, num_node_features] = [Num_points_in_cavity, 1]\n",
    "# pos : Node position matrix. [num_nodes, num_dimensions] = [Num_points_in_cavity, 3] \n",
    "def buildDataset(cavities):\n",
    "    dataset = [Data(\n",
    "                    pos = cav, \n",
    "                    x = torch.tensor([dict_features[k] for k in feats[idx]],\n",
    "                                     dtype=torch.get_default_dtype()).unsqueeze(1)) \n",
    "               for idx,cav in enumerate(cavities)]\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# Create batches. Decide whether applying rotation or not. \n",
    "def makeBatch(cavities, rotation = True):\n",
    "    # If false, dont apply rotation to the set the cavities. \n",
    "    if rotation == False:\n",
    "        dataset = buildDataset(cavities)\n",
    "    else:\n",
    "        dataset = buildDataset(applyRotation(cavities))\n",
    "    \n",
    "    # Return batch. Shuffle is set to False (default). \n",
    "    return next(iter(DataLoader(dataset, batch_size = len(dataset))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2976f0",
   "metadata": {},
   "source": [
    "### Building the network: Equivariant convolution\n",
    "\n",
    "The main operation of the convolution is the Fully Connected Tensor Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6e249180-f4c6-4e0f-939a-2ba89a9bc550",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution(torch.nn.Module):\n",
    "    def __init__(self, irreps_in, irreps_sh, irreps_out, num_neighbors) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_neighbors = num_neighbors\n",
    "        \n",
    "        # Required to know how many weights are required in the Multi-Layer Perceptron (MLP)\n",
    "        tp = FullyConnectedTensorProduct(\n",
    "            irreps_in1 = irreps_in,\n",
    "            irreps_in2 = irreps_sh,\n",
    "            irreps_out = irreps_out,\n",
    "            internal_weights = False,\n",
    "            shared_weights = False,\n",
    "        )\n",
    "        \n",
    "        # MLP: [Input, internal, and output dimensions], activation function\n",
    "        self.fc = FullyConnectedNet([3, 256, tp.weight_numel], torch.relu)\n",
    "        # Tensor product\n",
    "        self.tp = tp\n",
    "        # Visualize TP\n",
    "#         print('Fully Connected Tensor Product:', self.tp.visualize());\n",
    "#         plt.show()\n",
    "        \n",
    "        self.irreps_out = self.tp.irreps_out\n",
    "\n",
    "    def forward(self, node_features, edge_src, edge_dst, edge_attr, edge_scalars) -> torch.Tensor:\n",
    "        # To map the relative distances to the weights of the tensor product we will embed the distances\n",
    "        # using a basis function and then feed this embedding (edge_scalars) to a neural network. \n",
    "        weight = self.fc(edge_scalars)\n",
    "        # To compute this quantity per edges, so we will need to “lift” the input feature to the edges.\n",
    "        # For that we use edge_src that contains, for each edge, the index of the source node.\n",
    "        edge_features = self.tp(node_features[edge_src], edge_attr, weight)\n",
    "        # Sum over the neighbors. Get final output\n",
    "        node_features = scatter(edge_features, edge_dst, dim=0).div(self.num_neighbors**0.5)\n",
    "        \n",
    "        return node_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7778a4",
   "metadata": {},
   "source": [
    "### Building the network\n",
    "\n",
    "Now that convolution layer has been defined, we can fully construct our equivariant neural network for point clouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dfa907e9-f280-4f49-84c3-79ac20fb63cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        # Number of neighbors hyperparameter\n",
    "        self.num_neighbors = 3.8\n",
    "        \n",
    "        # Set the spherical harmonics \n",
    "        self.irreps_sh = o3.Irreps.spherical_harmonics(3)\n",
    "        irreps = self.irreps_sh\n",
    "\n",
    "        # First layer with gate\n",
    "        gate = Gate(\n",
    "            \"16x0e + 16x0o\", [torch.relu, torch.abs],  # scalar\n",
    "            \"8x0e + 8x0o + 8x0e + 8x0o\", [torch.relu, torch.tanh, torch.relu, torch.tanh],  # gates (scalars)\n",
    "            \"16x1o + 16x1e\"  # gated tensors, num_irreps has to match with gates\n",
    "        )\n",
    "        # Convolutional layer. Irreps_sh, irreps_sh, gate.irreps_in, num_neighbors\n",
    "        self.conv = Convolution(irreps, self.irreps_sh, gate.irreps_in, self.num_neighbors)\n",
    "        # Gate and its output\n",
    "        self.gate = gate\n",
    "        # irreps_out = irreps_scalars + (ElementWiseTensorProduct(irreps_gates, irreps_gated))\n",
    "        irreps = self.gate.irreps_out\n",
    "\n",
    "        # Final layer. gate ouput, irreps_sh, output specified, num_neighbors. \n",
    "        self.final = Convolution(irreps, self.irreps_sh, \"1x0e\", self.num_neighbors)\n",
    "        # Final output\n",
    "        self.irreps_out = self.final.irreps_out\n",
    "\n",
    "    def forward(self, data, nnodes, mradius) -> torch.Tensor:\n",
    "        # Set the number of nodes and max radius. \n",
    "        num_nodes = nnodes\n",
    "        max_radius = mradius\n",
    "        \n",
    "        # Generate graph using the node positions and creating the edges when the relative distance \n",
    "        # between a pair of nodes is smaller than max_radius (r).\n",
    "        edge_src, edge_dst = radius_graph(x = data.pos, r= max_radius, batch=data.batch)\n",
    "        edge_vec = data.pos[edge_src] - data.pos[edge_dst]\n",
    "        \n",
    "        # Computing the sh\n",
    "        # Normalize=True ensure that x is divided by |x| prior computation\n",
    "        edge_attr = o3.spherical_harmonics(\n",
    "            l=self.irreps_sh,\n",
    "            x=edge_vec,\n",
    "            normalize=True,\n",
    "            normalization='component'\n",
    "        )\n",
    "        \n",
    "        # Embed the distances then feed this embedding to the MLP (Convolutional class)\n",
    "        edge_length_embedded = soft_one_hot_linspace(\n",
    "            x=edge_vec.norm(dim=1),\n",
    "            start=0.5,\n",
    "            end=2.5,\n",
    "            number=3,\n",
    "            basis='smooth_finite',\n",
    "            cutoff=True\n",
    "        ) * 3**0.5\n",
    "        \n",
    "        x = scatter(edge_attr, edge_dst, dim=0).div(self.num_neighbors**0.5)\n",
    "        \n",
    "        # Network architecture:\n",
    "        \n",
    "        #CONV\n",
    "        x = self.conv(x, edge_src, edge_dst, edge_attr, edge_length_embedded)\n",
    "#         print('Conv output:', x.shape)\n",
    "#         print('Conv irreps_out:', self.conv.irreps_out, '\\n')\n",
    "        \n",
    "        #GATE\n",
    "        x = self.gate(x)\n",
    "#         print('Gate output:', x.shape)\n",
    "#         print('Gate irreps_in:', self.gate.irreps_in)\n",
    "#         print('Gate irreps_out:', self.gate.irreps_out, '\\n')\n",
    "        \n",
    "        #FINAL (CONV)\n",
    "        x = self.final(x, edge_src, edge_dst, edge_attr, edge_length_embedded)\n",
    "#         print('Final(conv) output:', x.shape)\n",
    "#         print('Final irreps_out:', self.final.irreps_out)\n",
    "        \n",
    "        \n",
    "        return scatter(x, data.batch, dim=0).div(num_nodes**0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c62b1a8",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a65ab48b-622a-4ad6-aab7-273a4af404a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(cavities, labels, num_nodes, max_radius):\n",
    "    #Set the number of epochs\n",
    "    NUM_EPOCHS = 1000\n",
    "    EPOCH_BATCH_SIZE = 250\n",
    "    accs = []\n",
    "    \n",
    "    # Train and test batches have suffered different rotations. Labels remain equal. \n",
    "    x, y = cavities, labels\n",
    "    train_x, train_y = makeBatch(x), labels\n",
    "    test_x, test_y = makeBatch(x), labels\n",
    "    print('Batch created:', train_x)\n",
    "    \n",
    "    # Build model\n",
    "    print(\"Model built.\")\n",
    "    net = Network()\n",
    "    \n",
    "    #Set the optimizer\n",
    "    optim = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "    \n",
    "    for step in tqdm(range(NUM_EPOCHS)):\n",
    "        pred = net(train_x, num_nodes, max_radius)\n",
    "        loss = (pred - train_y).pow(2).sum()\n",
    "        \n",
    "        # Update network parameters\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        if step % EPOCH_BATCH_SIZE == 0:\n",
    "            accuracy = net(test_x, num_nodes, max_radius).round().eq(test_y).all(dim=1).double().mean(dim=0).item()\n",
    "            print(f\"epoch {step:5d} | loss {loss:<10.1f} | {100 * accuracy:5.1f}% accuracy\")  \n",
    "            accs.append(accuracy) \n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "88d6f7f7-969d-45f8-9b2b-5fc38609b386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch created: DataBatch(x=[629, 1], pos=[629, 3], batch=[629], ptr=[27])\n",
      "Model built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:00<10:36,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     0 | loss 33.8       |  65.4% accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 260/1000 [00:05<00:15, 46.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   250 | loss 0.3        | 100.0% accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 510/1000 [00:10<00:09, 49.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   500 | loss 0.1        | 100.0% accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 760/1000 [00:15<00:04, 49.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   750 | loss 0.1        | 100.0% accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:19<00:00, 50.13it/s]\n"
     ]
    }
   ],
   "source": [
    "net = main(pockets, p_labels, 4, 1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efb4e23-ee56-45d2-8a1a-27c5df19234e",
   "metadata": {},
   "source": [
    "The network manages to identify rotated non druggable/druggable cavities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59d7bb6-7fb5-4c7a-81ff-af151d1556eb",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Model will be tested against rotated and non-rotated sets of pockets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3013479a-bb0b-4417-a611-a1c89bf14297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.],\n",
      "        [-0.],\n",
      "        [-0.],\n",
      "        [-0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [-0.],\n",
      "        [0.],\n",
      "        [-0.],\n",
      "        [-0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [-0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [-0.],\n",
      "        [1.],\n",
      "        [-0.]], grad_fn=<RoundBackward0>)\n"
     ]
    }
   ],
   "source": [
    "prediction = net(makeBatch(pockets, False), 4, 1.5)\n",
    "print(prediction.round())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b5a23a-3924-4655-a4d7-1f950469d26e",
   "metadata": {},
   "source": [
    "When the network is tested against a set of **non-rotated cavities**, we obtain a **100% accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7c8e4e85-714e-4aa3-aea5-c84c15e8d056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random matrix: tensor([[[ 0.5833, -0.8113, -0.0400],\n",
      "         [ 0.7226,  0.5407, -0.4307],\n",
      "         [ 0.3711,  0.2224,  0.9016]]])\n",
      "tensor([[-0.],\n",
      "        [-0.],\n",
      "        [-0.],\n",
      "        [-0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [-0.],\n",
      "        [0.],\n",
      "        [-0.],\n",
      "        [-0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [-0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [-0.],\n",
      "        [1.],\n",
      "        [-0.]], grad_fn=<RoundBackward0>)\n"
     ]
    }
   ],
   "source": [
    "prediction = net(makeBatch(pockets), 4, 1.5)\n",
    "print(prediction.round())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c49118-d9c3-4076-a252-5acf9b3e4d95",
   "metadata": {},
   "source": [
    "When the network is tested against a set of **rotated cavities**, we obtain a **100% accuracy**. Each time *makeBatch()* is called, a new rotation is applied to the original set of coordinates."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
