{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2dd52bb",
   "metadata": {},
   "source": [
    "# Learning proteins pockets shape: E3NN\n",
    "\n",
    "Under development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7607ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Current folder at which the notebook is located \n",
    "current_folder = globals()['_dh'][0]\n",
    "abs_path = '/'.join([p for p in current_folder.split('/')[:-1]])+'/'\n",
    "\n",
    "sys.path.insert(0, abs_path + 'funcs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46127f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from importlib import reload\n",
    "\n",
    "from torch_cluster import radius_graph\n",
    "from torch_geometric.data import Data\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch_scatter import scatter\n",
    "\n",
    "#e3nn\n",
    "import e3nn\n",
    "from e3nn import o3\n",
    "from e3nn.nn import FullyConnectedNet, Gate\n",
    "from e3nn.o3 import FullyConnectedTensorProduct\n",
    "from e3nn.math import soft_one_hot_linspace\n",
    "\n",
    "import data_funcs\n",
    "from data_funcs import *\n",
    "\n",
    "reload(data_funcs);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7550c792",
   "metadata": {},
   "source": [
    "## E3NN: Load curated data\n",
    "\n",
    "Retrieve all the data from the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e45359f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "cavs_train = torch.load(abs_path + 'data/Cavities/train_cavities.pt')\n",
    "labels_train = torch.FloatTensor(torch.load(abs_path + 'data/Labels/train_labels.pt')).unsqueeze(1)\n",
    "atypes_train = torch.load(abs_path + 'data/Features/train_atypes.pt')\n",
    "train_fp_features = torch.load(abs_path + 'data/Features/train_features.pt')\n",
    "\n",
    "# Load test data \n",
    "cavs_test = torch.load(abs_path + 'data/Cavities/test_cavities.pt')\n",
    "labels_test = torch.FloatTensor(torch.load(abs_path + 'data/Labels/test_labels.pt')).unsqueeze(1)\n",
    "atypes_test = torch.load(abs_path + 'data/Features/test_atypes.pt')\n",
    "test_fp_features = torch.load(abs_path + 'data/Features/test_features.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332892f1",
   "metadata": {},
   "source": [
    "Create the datasets based on all the data previously loaded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e0ee6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary dataset is generated to later split in training and validation splits \n",
    "temp_dataset = buildDataset(cavs_train, labels_train, atypes_train, train_fp_features)\n",
    "test_dataset = buildDataset(cavs_test, labels_test, atypes_test, test_fp_features)\n",
    "\n",
    "train_size = int(len(cavs_train)*0.9)\n",
    "train_dataset, val_dataset = random_split(temp_dataset, [train_size, len(cavs_train)-train_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256f0233",
   "metadata": {},
   "source": [
    "#### Info checkup \n",
    "- Check percentage of druggable cavities in every dataset (TBD)\n",
    "- Gate tuning (temporary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aeb0b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of druggable cavities in the test set: 0.0%\n"
     ]
    }
   ],
   "source": [
    "# # % druggable cavities in the test set \n",
    "# drug_test = round((len(np.where(y_test>0)[0])/len(y_test))*100, 2)\n",
    "# print(f'Percentage of druggable cavities in the test set: {drug_test}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84640330",
   "metadata": {},
   "source": [
    "## E3NN: Equivariant convolution\n",
    "\n",
    "The main operation of the convolution is the Fully Connected Tensor Product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1dc44ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution(torch.nn.Module):\n",
    "    def __init__(self, irreps_in, irreps_sh, irreps_out, num_neighbors) -> None:\n",
    "        super().__init__()\n",
    "        self.num_neighbors = num_neighbors\n",
    "        \n",
    "        # Required to know how many weights are required in the Multi-Layer Perceptron (MLP)\n",
    "        tp = FullyConnectedTensorProduct(\n",
    "            irreps_in1 = irreps_in,\n",
    "            irreps_in2 = irreps_sh,\n",
    "            irreps_out = irreps_out,\n",
    "            internal_weights = False,\n",
    "            shared_weights = False,\n",
    "        )\n",
    "        \n",
    "        # MLP: [Input, internal, and output dimensions], activation function\n",
    "        self.fc = FullyConnectedNet([3, 256, tp.weight_numel], torch.relu)\n",
    "        # Tensor product\n",
    "        self.tp = tp\n",
    "        self.irreps_out = self.tp.irreps_out\n",
    "\n",
    "    def forward(self, node_features, edge_src, edge_dst, edge_attr, edge_scalars) -> torch.Tensor:\n",
    "        # To map the relative distances to the weights of the tensor product we will embed the distances\n",
    "        # using a basis function and then feed this embedding (edge_scalars) to a neural network. \n",
    "        weight = self.fc(edge_scalars)\n",
    "        # To compute this quantity per edges, so we will need to “lift” the input feature to the edges.\n",
    "        # For that we use edge_src that contains, for each edge, the index of the source node.\n",
    "        edge_features = self.tp(node_features[edge_src], edge_attr, weight)\n",
    "        # Sum over the neighbors. Get final output\n",
    "        node_features = scatter(edge_features, edge_dst, dim=0).div(self.num_neighbors**0.5)\n",
    "        \n",
    "        return node_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc0b64d",
   "metadata": {},
   "source": [
    "# E3NN: Building the network\n",
    "\n",
    "Now that convolution layer has been defined, we can fully construct our equivariant neural network for point clouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "69732bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        # Set the device\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # Number of neighbors hyperparameter\n",
    "        self.num_neighbors = 3.8\n",
    "        \n",
    "        # Set the spherical harmonics \n",
    "        self.irreps_sh = o3.Irreps.spherical_harmonics(3)\n",
    "\n",
    "        # 160 -> 128\n",
    "        gate = Gate(\n",
    "            \"16x0e + 16x0o\", [torch.relu, torch.abs],  # scalar\n",
    "            \"8x0e + 8x0o + 8x0e + 8x0o\", [torch.relu, torch.tanh, torch.relu, torch.tanh],  # gates (scalars)\n",
    "            \"16x1o + 16x1e\"  # gated tensors, num_irreps has to match with gates\n",
    "        )\n",
    "        # 128 -> 104\n",
    "        gate2 = Gate(\n",
    "            \"16x0e + 16x0o\", [torch.relu, torch.abs],  # scalar\n",
    "            \"6x0e + 6x0o + 6x0e + 6x0o\", [torch.relu, torch.tanh, torch.relu, torch.tanh],  # gates (scalars)\n",
    "            \"12x1o + 12x1e\"  # gated tensors, num_irreps has to match with gates\n",
    "        )\n",
    "        # 104 -> 88\n",
    "        gate3 = Gate(\n",
    "            \"20x0e + 20x0o\", [torch.relu, torch.abs],  # scalar\n",
    "            \"4x0e + 4x0o + 4x0e + 4x0o\", [torch.relu, torch.tanh, torch.relu, torch.tanh],  # gates (scalars)\n",
    "            \"8x1o + 8x1e\"  # gated tensors, num_irreps has to match with gates\n",
    "        )\n",
    "        \n",
    "        # Gate. irreps_out = irreps_scalars + (ElementWiseTensorProduct(irreps_gates, irreps_gated))\n",
    "        self.gate = gate\n",
    "        self.gate2 = gate2\n",
    "        self.gate3 = gate3\n",
    "        \n",
    "        # Convolutional layer. Irreps_sh, irreps_sh, gate.irreps_in, num_neighbors\n",
    "        self.conv = Convolution(self.irreps_sh, self.irreps_sh, gate.irreps_in, self.num_neighbors)\n",
    "        \n",
    "        # Second convolutional layer \n",
    "        self.conv2 = Convolution(self.gate.irreps_out, self.irreps_sh, self.gate2.irreps_in, self.num_neighbors)\n",
    "        \n",
    "        # Third convolutional layer \n",
    "        self.conv3 = Convolution(self.gate2.irreps_out, self.irreps_sh, self.gate3.irreps_in, self.num_neighbors)\n",
    "        \n",
    "        # Final layer. gate ouput, irreps_sh, output specified, num_neighbors. \n",
    "        self.final = Convolution(self.gate3.irreps_out, self.irreps_sh, \"1x0e\", self.num_neighbors)\n",
    "        \n",
    "        # Final output\n",
    "        self.irreps_out = self.final.irreps_out\n",
    "\n",
    "        # Sigmoid\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "        # Linear \n",
    "        self.linear = torch.nn.Linear(gate_shape(self.gate3, 'out') + 12 , 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, data, prnt = False) -> torch.Tensor:\n",
    "        # Set the number of nodes and max radius.\n",
    "        num_nodes = 4\n",
    "        max_radius = 6.1\n",
    "        \n",
    "        # Generate graph using the node positions and creating the edges when the relative distance \n",
    "        # between a pair of nodes is smaller than max_radius (r).\n",
    "        edge_src, edge_dst = radius_graph(x = data.pos, r = max_radius, batch=data.batch)\n",
    "        edge_vec = data.pos[edge_src] - data.pos[edge_dst]\n",
    "\n",
    "        # Computing the sh\n",
    "        # Normalize=True ensure that x is divided by |x| prior computation\n",
    "        edge_attr = o3.spherical_harmonics(\n",
    "            l=self.irreps_sh,\n",
    "            x=edge_vec,\n",
    "            normalize=True,\n",
    "            normalization='component'\n",
    "        )\n",
    "        \n",
    "        # Embed the distances then feed this embedding to the MLP (Convolutional class)\n",
    "        edge_length_embedded = soft_one_hot_linspace(\n",
    "            x=edge_vec.norm(dim=1),\n",
    "            start=0.5,\n",
    "            end=2.5,\n",
    "            number=3,\n",
    "            basis='smooth_finite',\n",
    "            cutoff=True\n",
    "        ) * 3**0.5\n",
    "\n",
    "#         print('Edge dst:', edge_dst.shape)\n",
    "#         print('data.batch length:', len(data.batch))\n",
    "#         print('unique nodes:', len(np.unique(edge_dst)))\n",
    "#         print('Edge attributes:', edge_attr.shape)\n",
    "#         print('Edge length emb:', edge_length_embedded.shape)\n",
    "        \n",
    "        # Data must be loaded into GPU\n",
    "        edge_src = edge_src.to(self.device)\n",
    "        edge_dst = edge_dst.to(self.device)\n",
    "        edge_attr = edge_attr.to(self.device)\n",
    "        edge_length_embedded = edge_length_embedded.to(self.device)\n",
    "        data.batch = data.batch.to(self.device)\n",
    "        \n",
    "        #---------------------- LAYERS + GATES --------------------------\n",
    "        x = scatter(edge_attr, edge_dst, dim=0).div(self.num_neighbors**0.5)\n",
    "        if prnt is True:\n",
    "            print('1- Scatter:', x.shape)\n",
    "\n",
    "        x = self.conv(x, edge_src, edge_dst, edge_attr, edge_length_embedded)\n",
    "        if prnt is True:\n",
    "            print('2- Conv:', x.shape)\n",
    "        \n",
    "        x = self.gate(x)\n",
    "        if prnt is True:\n",
    "            print('3- Gate:', x.shape)    \n",
    "        \n",
    "        x = self.conv2(x, edge_src, edge_dst, edge_attr, edge_length_embedded)\n",
    "        if prnt is True:\n",
    "            print('4- Conv:', x.shape)\n",
    "\n",
    "        x = self.gate2(x)\n",
    "        if prnt is True:\n",
    "            print('5- Gate:', x.shape)\n",
    "        \n",
    "        x = self.conv3(x, edge_src, edge_dst, edge_attr, edge_length_embedded)\n",
    "        if prnt is True:\n",
    "            print('6- Conv:', x.shape)\n",
    "            \n",
    "        x = self.gate3(x)\n",
    "        if prnt is True:\n",
    "            print('7- Gate:', x.shape)\n",
    "\n",
    "        x = self.final(x, edge_src, edge_dst, edge_attr, edge_length_embedded)\n",
    "        if prnt is True:\n",
    "            print('8- Conv:', x.shape)        \n",
    "\n",
    "        x = scatter(x, data.batch, dim=0).div(num_nodes**0.5)\n",
    "        if prnt is True:\n",
    "            print('9- Scatter:', x.shape,'\\n')\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a944fff9",
   "metadata": {},
   "source": [
    "## E3NN: Training the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7d8a36cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping():\n",
    "    def __init__(self, tolerance = 5, min_delta = 0):\n",
    "        self.tolerance = tolerance\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "        \n",
    "    def __call__(self, train_loss, validation_loss):\n",
    "        if(validation_loss - train_loss) > self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.tolerance:\n",
    "                self.early_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9c15be55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(train_loader, net, criterion, optimizer, device):\n",
    "    running_tloss = 0.0\n",
    "    for idx, batch in enumerate(train_loader):\n",
    "        inputs, labels = batch\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Zero gradients for every batch\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize.\n",
    "        pred = net(inputs, False)\n",
    "        loss = criterion(pred, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate batch losses\n",
    "        running_tloss += loss.item()\n",
    "\n",
    "    # Loss per batch\n",
    "    avg_loss = running_tloss / (idx + 1) \n",
    "\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def validate_one_epoch(val_loader, net, criterion, device):\n",
    "    running_vloss = 0.0\n",
    "    for idx, val_batch in enumerate(val_loader):\n",
    "        val_inputs, val_labels = val_batch\n",
    "        val_labels.to(device)\n",
    "        val_preds = net(val_inputs)\n",
    "        val_loss = criterion(val_preds, val_labels)\n",
    "        running_vloss += val_loss.item()\n",
    "    \n",
    "    # Loss per batch\n",
    "    avg_loss = running_vloss / (idx + 1)\n",
    "\n",
    "    return avg_loss\n",
    "\n",
    "def train(net, train_loader, val_loader, device):\n",
    "    print(f\"Training on {device}.\")\n",
    "    \n",
    "    timestamp = datetime.now().strftime('%Y_%m_%d_%H%M%S')\n",
    "    writer = SummaryWriter(f'runs/{timestamp}')\n",
    "    \n",
    "    #Set the number of epochs + get number of batches\n",
    "    NUM_EPOCHS = 2000\n",
    "    \n",
    "    # Set the optimizer, criterion, and early stopping criteria. \n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    early_stopping = EarlyStopping(5, 2)\n",
    "    \n",
    "    for step in tqdm(range(NUM_EPOCHS)):\n",
    "        net.train()\n",
    "        train_avg_loss = train_one_epoch(train_loader, net, criterion, optimizer, device)\n",
    "        net.train(False)\n",
    "        val_avg_loss = validate_one_epoch(val_loader, net, criterion, device)\n",
    "        early_stopping(train_avg_loss, val_avg_loss)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            print(f'Training finished at epoch {step+1}')\n",
    "            break\n",
    "        \n",
    "        # Tensorboard stats \n",
    "        writer.add_scalars('Train vs. Val Loss',\n",
    "                            {'Training':train_avg_loss, 'Validation': val_avg_loss}, step + 1)\n",
    "        writer.flush()\n",
    "\n",
    "        # Print stats every N epochs\n",
    "        if (step+1)%25 == 0:\n",
    "            print(f'Epoch: {step+1} | Training Loss: {train_avg_loss:.3f} | Validation Loss: {val_avg_loss:.3f}')\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9894ee",
   "metadata": {},
   "source": [
    "#### Train the model using early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "13137dbb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▉                                      | 25/1000 [03:45<2:27:22,  9.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 | Training Loss: 479.168 | Validation Loss: 7.639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█                                      | 26/1000 [03:56<2:27:35,  9.09s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gv/z7k0kt1s7wx10fl8kbfr15cr0000gn/T/ipykernel_76986/723851251.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/gv/z7k0kt1s7wx10fl8kbfr15cr0000gn/T/ipykernel_76986/2353885048.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, train_loader, val_loader, device)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mtrain_avg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mval_avg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/gv/z7k0kt1s7wx10fl8kbfr15cr0000gn/T/ipykernel_76986/2353885048.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(train_loader, net, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# forward + backward + optimize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/shapes/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/gv/z7k0kt1s7wx10fl8kbfr15cr0000gn/T/ipykernel_76986/4128976452.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data, prnt)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'5- Gate:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_dst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_length_embedded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprnt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'6- Conv:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/shapes/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/gv/z7k0kt1s7wx10fl8kbfr15cr0000gn/T/ipykernel_76986/60165358.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, node_features, edge_src, edge_dst, edge_attr, edge_scalars)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# To map the relative distances to the weights of the tensor product we will embed the distances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# using a basis function and then feed this embedding (edge_scalars) to a neural network.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_scalars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;31m# To compute this quantity per edges, so we will need to “lift” the input feature to the edges.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# For that we use edge_src that contains, for each edge, the index of the source node.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/shapes/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/shapes/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/shapes/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/shapes/lib/python3.9/site-packages/e3nn/nn/_fc.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh_in\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_in\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Network()\n",
    "model.to(device)\n",
    "\n",
    "# Generate train and validation dataloaders\n",
    "train_loader = makeLoader(train_dataset, 64)\n",
    "val_loader = makeLoader(val_dataset, 32)\n",
    "\n",
    "# Train the model\n",
    "model = train(model, train_loader, val_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f5c1c0",
   "metadata": {},
   "source": [
    "## E3NN: Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03c441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, test_loader, device):\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            inputs, y_true = batch\n",
    "            y_true = y_true.to(device)\n",
    "            y_pred = net(inputs)\n",
    "            loss = criterion(y_pred, y_true)\n",
    "            accuracy = y_pred.round().eq(y_true).all(dim=1).double().mean(dim=0).item()*100\n",
    "            auc = roc_auc_score(y_true, y_pred)\n",
    "            print(f'Accuracy: {accuracy:.3f}% | AUC:{auc} | Loss: {loss:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06c1b81",
   "metadata": {},
   "source": [
    "Testing against an unseen set of cavities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7730c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_loader = makeLoader(test_dataset, 1000)\n",
    "test(test_loader, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f66a77",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "f66b9c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), abs_path + 'data/Models/1a_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b7d7e016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.3 %\n",
      "AUC: 0.7\n"
     ]
    }
   ],
   "source": [
    "pred_test = new_model(makeBatch(X_test, atypes_test, test_fp_features))\n",
    "print('Accuracy:',round(pred_test.round().eq(y_test).all(dim=1).double().mean(dim=0).item()*100, 1),'%')\n",
    "y_true = y_test.numpy()\n",
    "y_pred = pred_test.round().detach().numpy()\n",
    "print('AUC:', roc_auc_score(y_true, y_pred))\n",
    "\n",
    "# Visualize results\n",
    "# plot_confusion_matrix(cf_matrix, 'test')\n",
    "# plot_roc_curve(y_true, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
